{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('leafdata/train.csv')\n",
    "test = pd.read_csv('leafdata/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train, test):\n",
    "    label_encoder = LabelEncoder().fit(train.species)\n",
    "    labels = label_encoder.transform(train.species)\n",
    "    classes = list(label_encoder.classes_)\n",
    "\n",
    "    train = train.drop(['species', 'id'], axis=1)\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    return train, labels, test, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, labels, test, classes = encode(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize train features\n",
    "scaler = StandardScaler().fit(train.values)\n",
    "scaled_train = scaler.transform(train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data into train and validation\n",
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\n",
    "for train_index, valid_index in sss.split(scaled_train, labels):\n",
    "    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n",
    "    y_train, y_valid = labels[train_index], labels[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = 64 # number of features per features type (shape, texture, margin)   \n",
    "nb_class = len(classes)\n",
    "\n",
    "# reshape train data\n",
    "X_train_r = np.zeros((len(X_train), nb_features, 3))\n",
    "X_train_r[:, :, 0] = X_train[:, :nb_features]\n",
    "X_train_r[:, :, 1] = X_train[:, nb_features:128]\n",
    "X_train_r[:, :, 2] = X_train[:, 128:]\n",
    "\n",
    "# reshape validation data\n",
    "X_valid_r = np.zeros((len(X_valid), nb_features, 3))\n",
    "X_valid_r[:, :, 0] = X_valid[:, :nb_features]\n",
    "X_valid_r[:, :, 1] = X_valid[:, nb_features:128]\n",
    "X_valid_r[:, :, 2] = X_valid[:, 128:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0116 22:26:29.647589  5532 deprecation_wrapper.py:119] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(64, 3), filters=512, kernel_size=1)`\n",
      "  \"\"\"\n",
      "W0116 22:26:29.672612  5532 deprecation_wrapper.py:119] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0116 22:26:29.675615  5532 deprecation_wrapper.py:119] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0116 22:26:29.698635  5532 deprecation_wrapper.py:119] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0116 22:26:29.704641  5532 deprecation.py:506] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0116 22:26:29.750683  5532 deprecation_wrapper.py:119] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0116 22:26:29.756688  5532 deprecation_wrapper.py:119] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keras model with one Convolution1D layer\n",
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n",
      "W0116 22:26:38.169902  5532 deprecation.py:323] From c:\\users\\sam\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 99 samples\n",
      "Epoch 1/15\n",
      "891/891 [==============================] - 26s 29ms/step - loss: 3.6630 - acc: 0.2469 - val_loss: 1.4671 - val_acc: 0.7475\n",
      "Epoch 2/15\n",
      "891/891 [==============================] - 24s 27ms/step - loss: 0.6717 - acc: 0.8384 - val_loss: 0.3073 - val_acc: 0.9091\n",
      "Epoch 3/15\n",
      "891/891 [==============================] - 24s 27ms/step - loss: 0.1391 - acc: 0.9787 - val_loss: 0.4174 - val_acc: 0.9192\n",
      "Epoch 4/15\n",
      "891/891 [==============================] - 24s 27ms/step - loss: 0.2014 - acc: 0.9854 - val_loss: 0.3785 - val_acc: 0.9192\n",
      "Epoch 5/15\n",
      "891/891 [==============================] - 24s 27ms/step - loss: 0.1779 - acc: 0.9865 - val_loss: 0.2796 - val_acc: 0.9495\n",
      "Epoch 6/15\n",
      "891/891 [==============================] - 24s 27ms/step - loss: 0.1919 - acc: 0.9877 - val_loss: 0.2895 - val_acc: 0.9495\n",
      "Epoch 7/15\n",
      "891/891 [==============================] - 24s 27ms/step - loss: 0.1876 - acc: 0.9854 - val_loss: 0.2838 - val_acc: 0.9596\n",
      "Epoch 8/15\n",
      "891/891 [==============================] - 27s 30ms/step - loss: 0.1750 - acc: 0.9888 - val_loss: 0.3033 - val_acc: 0.9495\n",
      "Epoch 9/15\n",
      "891/891 [==============================] - 28s 31ms/step - loss: 0.1677 - acc: 0.9888 - val_loss: 0.2742 - val_acc: 0.9596\n",
      "Epoch 10/15\n",
      "891/891 [==============================] - 26s 30ms/step - loss: 0.1653 - acc: 0.9899 - val_loss: 0.2740 - val_acc: 0.9596\n",
      "Epoch 11/15\n",
      "891/891 [==============================] - 25s 28ms/step - loss: 0.1648 - acc: 0.9899 - val_loss: 0.2732 - val_acc: 0.9596\n",
      "Epoch 12/15\n",
      "891/891 [==============================] - 25s 28ms/step - loss: 0.1646 - acc: 0.9899 - val_loss: 0.2743 - val_acc: 0.9596\n",
      "Epoch 13/15\n",
      "891/891 [==============================] - 25s 28ms/step - loss: 0.1643 - acc: 0.9899 - val_loss: 0.2727 - val_acc: 0.9596\n",
      "Epoch 14/15\n",
      "891/891 [==============================] - 25s 28ms/step - loss: 0.1642 - acc: 0.9899 - val_loss: 0.2691 - val_acc: 0.9596\n",
      "Epoch 15/15\n",
      "891/891 [==============================] - 25s 28ms/step - loss: 0.1640 - acc: 0.9899 - val_loss: 0.2706 - val_acc: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f955ef94e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 15\n",
    "model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1787c684cd91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    " print(hist.history.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
